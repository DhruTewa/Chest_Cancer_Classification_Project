{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dhruv/PROJECTS/Kaggle_Projects/Chest_Cancer_Classification_Project'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_type: str\n",
    "    kaggle_dataset_owner: str\n",
    "    kaggle_dataset_name: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,) :\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config=self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_type = config.source_type,\n",
    "            kaggle_dataset_owner = config.kaggle_dataset_owner,\n",
    "            kaggle_dataset_name = config.kaggle_dataset_name,\n",
    "            local_data_file = config.local_data_file,\n",
    "            unzip_dir = config.unzip_dir\n",
    "        )\n",
    "        return data_ingestion_config    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def download_file(self) -> str:\n",
    "        # Authenticate with Kaggle API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        logger.info(f\"Kaggle API Authenticated\")\n",
    "        \n",
    "        try: \n",
    "            dataset_url = f\"{self.config.kaggle_dataset_owner}/{self.config.kaggle_dataset_name}\"\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "            api.dataset_download_files(dataset_url, path=zip_download_dir, unzip=False)\n",
    "            logger.info(f\"Downloaded dataset from kaggle to {zip_download_dir}\")\n",
    "            #logger.info(f\"Downloaded dataset from kaggle to {self.config.root_dir}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        zip_file_path = os.path.join(self.config.local_data_file,'chest-ctscan-images.zip')\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)  \n",
    "\n",
    "\n",
    "        # Delete unnecessary folders (test and valid)\n",
    "        folders_to_delete = ['test', 'valid']\n",
    "        for folder in folders_to_delete:\n",
    "            extract_path = os.path.join(unzip_path, 'Data')\n",
    "            folder_path = os.path.join(extract_path, folder)\n",
    "            if os.path.exists(folder_path):\n",
    "                shutil.rmtree(folder_path)\n",
    "            else:\n",
    "                print(f\"Folder {folder} does not exist.\")\n",
    "                \n",
    "        files_to_move_and_rename = [\n",
    "            {'name': 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'new_name': 'adenocarcinoma'},\n",
    "            {'name': 'normal', 'new_name': 'normal'}\n",
    "        ]  # Update with your file names and new names\n",
    "\n",
    "        # Loop through the files to move and rename\n",
    "        for file in files_to_move_and_rename:\n",
    "            # Get the path to the current file\n",
    "            file_path = os.path.join(unzip_path, 'Data','train', file['name'])\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if os.path.exists(file_path):\n",
    "                # Move the file to the zip file path and rename it\n",
    "                new_file_path = os.path.join(os.path.dirname(self.config.local_data_file), 'Data')\n",
    "                shutil.move(file_path, new_file_path)\n",
    "                \n",
    "            else:\n",
    "                print(f\"File {file['name']} does not exist.\")\n",
    "        shutil.rmtree(os.path.join(unzip_path, 'Data','train')) # Remove the train folder\n",
    "\n",
    "        \n",
    "        logger.info(f\"Extracted dataset to {unzip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-25 20:32:00,325: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-08-25 20:32:00,327: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-25 20:32:00,328: INFO: common: created directory at: artifacts]\n",
      "[2024-08-25 20:32:00,328: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/dhruv/.kaggle/kaggle.json'\n",
      "[2024-08-25 20:32:00,332: INFO: 2990488593: Kaggle API Authenticated]\n",
      "[2024-08-25 20:32:00,333: INFO: 2990488593: Downloading data from mohamedhanyyy/chest-ctscan-images into file artifacts/data_ingestion/]\n",
      "Dataset URL: https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images\n",
      "[2024-08-25 20:32:02,137: INFO: 2990488593: Downloaded dataset from kaggle to artifacts/data_ingestion/]\n",
      "[2024-08-25 20:32:02,785: INFO: 2990488593: Extracted dataset to artifacts/data_ingestion/]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-25 16:46:36,508: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-08-25 16:46:36,510: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-25 16:46:36,511: INFO: common: created directory at: artifacts]\n",
      "[2024-08-25 16:46:36,512: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "{'artifacts/data_ingestion/'} {'artifacts/data_ingestion/chest-ctscan-images.zip'}\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "unzip_path =data_ingestion.config.unzip_dir\n",
    "zip_file_path = os.path.join(data_ingestion.config.local_data_file,'chest-ctscan-images.zip')\n",
    "#zip_file_path = data_ingestion.config.local_data_file\n",
    "print({unzip_path},{zip_file_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_path) \n",
    "\n",
    "# Delete unnecessary folders (test and valid)\n",
    "folders_to_delete = ['test', 'valid']\n",
    "for folder in folders_to_delete:\n",
    "    extract_path = os.path.join(unzip_path, 'Data')\n",
    "    folder_path = os.path.join(extract_path, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "    else:\n",
    "        print(f\"Folder {folder} does not exist.\")\n",
    "        \n",
    "files_to_move_and_rename = [\n",
    "    {'name': 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'new_name': 'adenocarcinoma'},\n",
    "    {'name': 'normal', 'new_name': 'normal'}\n",
    "]  # Update with your file names and new names\n",
    "\n",
    "# Loop through the files to move and rename\n",
    "for file in files_to_move_and_rename:\n",
    "    # Get the path to the current file\n",
    "    file_path = os.path.join(unzip_path, 'Data','train', file['name'])\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Move the file to the zip file path and rename it\n",
    "        new_file_path = os.path.join(os.path.dirname(zip_file_path), 'Data')\n",
    "        shutil.move(file_path, new_file_path)\n",
    "        \n",
    "    else:\n",
    "        print(f\"File {file['name']} does not exist.\")\n",
    "shutil.rmtree(os.path.join(unzip_path, 'Data','train'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts/data_ingestion/Data/train/normal'} {'artifacts/data_ingestion/Data'}\n"
     ]
    }
   ],
   "source": [
    "# Define the files to move and rename in the Data folder\n",
    "os.rename(folder_path, new_folder_path)\n",
    "# Print a success message\n",
    "print({file_path},{new_file_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(os.path.join(unzip_path, 'Data','train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion/Data/train'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_path = os.path.join(unzip_path, 'Data','train')\n",
    "extract_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped, deleted and moved folders successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the files to move and rename in the Data folder\n",
    "files_to_move_and_rename = [\n",
    "    {'name': 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'new_name': 'adenocarcinoma'},\n",
    "    {'name': 'normal', 'new_name': 'normal'}\n",
    "]  # Update with your file names and new names\n",
    "\n",
    "# Loop through the folders to delete and move\n",
    "for folder in files_to_move_and_rename:\n",
    "    # Get the path to the current folder\n",
    "    folder_path = os.path.join(unzip_path, 'Data', folder['name'])\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # Move the folder to the zip file path and rename it\n",
    "        new_folder_path = os.path.join(new_folder_path,'Data',os.path.dirname(folder['new_name']))\n",
    "        shutil.move(folder_path, new_folder_path)\n",
    "    else:\n",
    "        print(f\"Folder {folder['name']} does not exist.\")\n",
    "\n",
    "# Print a success message\n",
    "print(\"Unzipped, deleted and moved folders successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts/data_ingestion/Data/train/normal'} {'artifacts/data_ingestion/normal/Data/'}\n"
     ]
    }
   ],
   "source": [
    "#folders_to_delete = ['large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa']\n",
    "files_to_move_and_rename = [\n",
    "    {'name': 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'new_name': 'adenocarcinoma'},\n",
    "    {'name': 'normal', 'new_name': 'normal'}\n",
    "]\n",
    "folder_path = os.path.join(unzip_path, 'Data', 'train', folder['name'])\n",
    "folder_path\n",
    "new_folder_path = os.path.join(new_folder_path,'Data',os.path.dirname(folder['new_name']))\n",
    "new_folder_path\n",
    "print({folder_path},{new_folder_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion/normal'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_folder_path = os.path.join(os.path.dirname(zip_file_path), folder['new_name'])\n",
    "new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion/Data/train'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = os.path.join(unzip_path,'Data')\n",
    "folder_path = os.path.join(extract_path, folder)\n",
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(os.path.join(extract_path, 'train'), extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
